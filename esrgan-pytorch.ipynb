{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Terminal","metadata":{}},{"cell_type":"code","source":"#!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n#!python pytorch-xla-env-setup.py --version 1.7 --apt-packages libomp5 libopenblas-dev\n#!pip install --quiet pytorch-lightning torchsummary","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-24T06:12:38.821182Z","iopub.execute_input":"2021-07-24T06:12:38.821603Z","iopub.status.idle":"2021-07-24T06:12:38.825465Z","shell.execute_reply.started":"2021-07-24T06:12:38.82156Z","shell.execute_reply":"2021-07-24T06:12:38.82447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Imports","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision import transforms, models\nfrom skimage import io, transform\nfrom torchsummary import summary\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nimport pytorch_lightning as pl\nimport torch.nn as nn\nimport numpy as np\nimport torch\nimport os, time","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:12:38.836335Z","iopub.execute_input":"2021-07-24T06:12:38.836605Z","iopub.status.idle":"2021-07-24T06:12:38.843813Z","shell.execute_reply.started":"2021-07-24T06:12:38.836578Z","shell.execute_reply":"2021-07-24T06:12:38.842991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Hyperparameters","metadata":{}},{"cell_type":"code","source":"img_size = 128\nbatch_size = 16","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:12:38.854617Z","iopub.execute_input":"2021-07-24T06:12:38.854867Z","iopub.status.idle":"2021-07-24T06:12:38.859352Z","shell.execute_reply.started":"2021-07-24T06:12:38.854842Z","shell.execute_reply":"2021-07-24T06:12:38.858488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Generator Blocks","metadata":{}},{"cell_type":"code","source":"lrelu = lambda x: nn.init.calculate_gain('leaky_relu', 0.2) * nn.LeakyReLU(0.2)(x)\n\ndef initialize_weights(m):\n    if isinstance(m, nn.Conv2d):\n        scale = 0.1\n        he_gain = (1 / np.prod(m.weight.shape[1:])) ** 0.5\n        nn.init.normal_(m.weight.data, std=scale*he_gain)\n        if m.bias is not None:\n            nn.init.constant_(m.bias.data, 0)\n    elif isinstance(m, nn.BatchNorm2d):\n        nn.init.constant_(m.weight.data, 1)\n        nn.init.constant_(m.bias.data, 0)\n    elif isinstance(m, nn.Linear):\n        nn.init.kaiming_uniform_(m.weight.data)\n        nn.init.constant_(m.bias.data, 0)\n            \nclass ScaledConv(nn.Conv2d):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\nclass ResBlock(nn.Module):\n    def __init__(self, nf=64):\n        super().__init__()\n        self.conv1 = ScaledConv(nf, nf, 3, padding=1)\n        self.conv2 = ScaledConv(nf, nf, 3, padding=1)\n    \n    def forward(self, inputs):\n        x = inputs\n        x = self.conv1(x)\n        x = F.relu(x)\n        x = self.conv2(x)\n        x = inputs + x\n        return x\n    \nclass DenseBlock(nn.Module):\n    def __init__(self, nf=64, gc=32): # gc - growth channel (intermediate)\n        super().__init__()\n        self.convs = nn.ModuleList([ScaledConv(nf + gc * i, gc, 3, padding=1) for i in range(4)])\n        self.final_conv = ScaledConv(nf + gc * 4, nf, 3, padding=1)\n    \n    def forward(self, inputs):\n        x = inputs\n        all_x = [x]\n        for conv in self.convs:\n            x = conv(torch.cat(all_x, dim=1))\n            x = lrelu(x)\n            all_x.append(x)\n        x = self.final_conv(torch.cat(all_x, dim=1))\n        return x\n\nclass RRDB(nn.Module):\n    def __init__(self, nf=64, gc=32, beta=0.2): # beta - residual scaling parameter\n        super().__init__()\n        self.dbs = nn.ModuleList([DenseBlock(nf, gc) for _ in range(3)])\n        self.beta = beta\n    \n    def forward(self, inputs):\n        x = inputs\n        for db in self.dbs:\n            x += self.beta * db(x)\n        x = inputs + self.beta * x\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:12:38.894528Z","iopub.execute_input":"2021-07-24T06:12:38.89478Z","iopub.status.idle":"2021-07-24T06:12:38.910635Z","shell.execute_reply.started":"2021-07-24T06:12:38.894756Z","shell.execute_reply":"2021-07-24T06:12:38.909472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Generator Arch","metadata":{}},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self, nblocks=23, block_type=RRDB):\n        super().__init__()\n        self.first_conv = ScaledConv(3, 64, 9, padding=4)\n        self.blocks = nn.Sequential(*[block_type() for _ in range(nblocks)])\n        self.end_block_conv = ScaledConv(64, 64, 3, padding=1)\n        self.up_convs = nn.Sequential(*[ScaledConv(64, 256, 9, padding=4) for _ in range(2)])\n        self.final_conv = ScaledConv(64, 3, 9, padding=4)\n        self.pix_shuf = nn.PixelShuffle(2)\n    \n    def forward(self, inputs):\n        x = inputs\n        x = self.first_conv(x)\n        x = lrelu(x)\n        before_block_state = x\n        \n        x = self.blocks(x)\n        \n        x = self.end_block_conv(x)\n        x = x + before_block_state\n        \n        for up_conv in self.up_convs:\n            x = up_conv(x)\n            x = self.pix_shuf(x)\n            x = lrelu(x)\n        \n        x = self.final_conv(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:12:38.925322Z","iopub.execute_input":"2021-07-24T06:12:38.925565Z","iopub.status.idle":"2021-07-24T06:12:38.93391Z","shell.execute_reply.started":"2021-07-24T06:12:38.925542Z","shell.execute_reply":"2021-07-24T06:12:38.932941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Discriminator Arch","metadata":{}},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self, hr_img_size=img_size):\n        super().__init__()\n        self.conv_filters = [64, 64, 128, 128, 256, 256, 512, 512]\n        self.strides = [1, 2] * 4\n        \n        self.first_conv = ScaledConv(3, 64, 9, padding=4)\n        self.convs = nn.Sequential(*[ScaledConv(\n            self.conv_filters[idx-1], self.conv_filters[idx],\n            3, stride=self.strides[idx], padding=1)\n                      for idx in range(1, len(self.conv_filters))])\n        self.bns = nn.ModuleList([nn.BatchNorm2d(nf) for nf in self.conv_filters[1:]])\n        \n        self.fc1 = nn.Linear((hr_img_size // 2 ** 4) ** 2 * self.conv_filters[-1], 1024)\n        self.fc2 = nn.Linear(1024, 1)\n    \n    def forward(self, inputs):\n        x = inputs\n        x = self.first_conv(x)\n        x = lrelu(x)\n        before_block_state = x\n        \n        for block_idx, block in enumerate(self.convs):\n            x = block(x)\n            x = self.bns[block_idx](x)\n            x = lrelu(x)\n        \n        print(x.shape)\n        x = torch.flatten(x, start_dim=1) # only flatten CHW in NCHW\n        x = self.fc1(x)\n        x = lrelu(x)\n        x = self.fc2(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:12:38.93875Z","iopub.execute_input":"2021-07-24T06:12:38.93905Z","iopub.status.idle":"2021-07-24T06:12:38.950538Z","shell.execute_reply.started":"2021-07-24T06:12:38.939022Z","shell.execute_reply":"2021-07-24T06:12:38.949589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Pretrain GAN","metadata":{}},{"cell_type":"code","source":"class PretrainGenerator(pl.LightningModule):\n    def __init__(self):\n        super().__init__()\n        self.gen = Generator()\n        self.gen.apply(initialize_weights)\n        self.l1 = nn.L1Loss()\n        self.epoch_num = 0\n        self.time = time.time()\n    \n    def forward(self, inputs):\n        return self.gen(inputs)\n    \n    def training_step(self, batch, batch_idx):\n        lr, hr = batch['lr'], batch['hr']\n        sr = self.gen(lr)\n        \n        gloss = self.l1(sr, hr)\n        return gloss\n        \n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.gen.parameters(), lr=1e-4 * batch_size / 16, betas=(0.9, 0.999))\n        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 2e5, gamma=0.5)\n        return [optimizer], [scheduler]\n\n    def training_epoch_end(self, outputs) -> None:\n        end_time = time.time()\n        duration = round(end_time - self.time)\n        print('Epoch {} ended | Time to complete: {}m {}s       \\r'.format(self.epoch_num, duration // 60, duration % 60), end='')\n        self.epoch_num += 1\n        self.time = end_time","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:12:38.952117Z","iopub.execute_input":"2021-07-24T06:12:38.952537Z","iopub.status.idle":"2021-07-24T06:12:38.964828Z","shell.execute_reply.started":"2021-07-24T06:12:38.952455Z","shell.execute_reply":"2021-07-24T06:12:38.963826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Adversarial GAN","metadata":{}},{"cell_type":"code","source":"class GAN(pl.LightningModule):\n    def __init__(self, pretrained_generator):\n        super().__init__()\n        self.gen = pretrained_generator\n        self.disc = Discriminator()\n        self.disc.apply(initialize_weights)\n        self.vgg = moels.vgg19(pretrained=True).features[:35] # 4th conv before 5th max pool\n        self.sig = nn.Sigmoid()\n        self.mse = nn.MSELoss()\n        self.l1 = nn.L1Loss()\n    \n    def forward(self, inputs): # idk not really needed\n        return inputs\n    \n    def d_ra(self, observed_preds, base_preds):\n        return self.sig(observed_preds - torch.mean(base_preds))\n    \n    def disc_loss(self, true_preds, fake_preds):\n        loss_real = -torch.mean(torch.log(self.d_ra(true_preds, fake_preds)))\n        loss_fake = -torch.mean(torch.log(1 - self.d_ra(fake_preds, real_preds)))\n        return loss_real + loss_fake\n    \n    def gen_loss(self, sr, hr, true_preds, fake_preds, lb=5e-3, eta=1e-2):\n        vgg_hr = self.vgg(hr)\n        vgg_sr = self.vgg(sr)\n        vgg_loss = self.mse(vgg_sr, vgg_hr)\n        \n        loss_real = -torch.mean(torch.log(1 - self.d_ra(true_preds, fake_preds)))\n        loss_fake = -torch.mean(torch.log(self.d_ra(fake_preds, real_preds)))\n        adv_loss = loss_real + loss_fake\n        \n        l1_loss = self.l1(sr, hr)\n        \n        return vgg_loss + lb * adv_loss + eta * l1_loss\n    \n    def training_step(self, batch, batch_idx, optimizer_idx):\n        lr, hr = batch\n        sr = self.gen(lr)\n        true_preds = self.disc(hr)\n        fake_preds = self.disc(sr)\n        \n        if optimizer_idx == 0:\n            gloss = gen_loss(sr, hr, true_preds, fake_preds)\n            tqdm_dict = {'g_loss': gloss}\n            output = {'loss': gloss, 'progress_bar': tqdm_dict, 'log': tqdm_dict}\n            return output\n        \n        if optimizer_idx == 1:\n            dloss = disc_loss(true_preds, fake_preds)\n            tqdm_dict = {'d_loss': dloss}\n            output = {'loss': dloss, 'progress_bar': tqdm_dict, 'log': tqdm_dict}\n            return output\n        \n    def configure_optimizers(self):\n        gen_opt = torch.optim.Adam(self.gen.parameters(), lr=1e-4 * batch_size / 16, betas=(0.9, 0.999))\n        gen_scheduler = torch.optim.lr_scheduler.MultiStepLR(gen_opt, [5e4, 1e5, 2e5, 3e5], gamma=0.5)\n        disc_opt = torch.optim.Adam(self.disc.parameters(), lr=1e-4 * batch_size / 16, betas=(0.9, 0.999))\n        disc_scheduler = torch.optim.lr_scheduler.MultiStepLR(disc_opt, [5e4, 1e5, 2e5, 3e5], gamma=0.5)\n        return [gen_opt, disc_opt], [gen_scheduler, disc_scheduler]","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:12:38.96646Z","iopub.execute_input":"2021-07-24T06:12:38.966822Z","iopub.status.idle":"2021-07-24T06:12:38.985946Z","shell.execute_reply.started":"2021-07-24T06:12:38.966785Z","shell.execute_reply":"2021-07-24T06:12:38.985157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Image Dataset","metadata":{}},{"cell_type":"code","source":"class SRDataset(Dataset):\n    def __init__(self, root_dir='/kaggle/input/art-sr', max_size=20000, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.max_size = max_size\n        self.img_filenames = os.listdir(os.path.join(root_dir, 'imgs32'))\n        self.img_filenames.sort()\n    \n    def __len__(self):\n        return min(len(self.img_filenames), int(batch_size * (self.max_size // batch_size)))\n    \n    def __getitem__(self, idx):\n        lr_img = io.imread(os.path.join(self.root_dir, 'imgs32', self.img_filenames[idx]))\n        hr_img = io.imread(os.path.join(self.root_dir, 'imgs128', self.img_filenames[idx]))\n        ret = {'lr': lr_img, 'hr': hr_img}\n\n        if self.transform:\n            ret = self.transform(ret)\n        \n        return ret\n\nclass ToTensor(object):\n    def __call__(self, sample):\n        lr, hr = sample['lr'], sample['hr']\n        \n        lr = (lr.transpose((2, 0, 1)) / 255.0).astype(np.float32) # HWC -> CHW\n        lr = torch.from_numpy(lr)\n        hr = (hr.transpose((2, 0, 1)) / 255.0).astype(np.float32) # HWC -> CHW\n        hr = torch.from_numpy(hr)\n        return {'lr': lr,\n                'hr': hr,\n               }\n\nclass SRDataModule(pl.LightningDataModule):\n    def __init__(self, train_test_split=0.9):\n        super().__init__()\n        self.dataset = SRDataset(\n            transform=transforms.Compose([ToTensor()])\n        )\n        \n        train_len = int(train_test_split * len(self.dataset))\n        val_len = len(self.dataset) - train_len\n        self.dataset_train, self.dataset_val = random_split(self.dataset, [train_len, val_len])\n    \n    def setup(self, stage=None):\n        dataset = SRDataset(\n            transform=transforms.Compose([ToTensor()])\n        )\n        \n        if stage == 'train' or stage is None:\n            self.dataset_train, self.dataset_val = random_split(self.dataset, [train_len, val_len])\n    \n    def train_dataloader(self):\n        return DataLoader(self.dataset_train, batch_size=batch_size, shuffle=True, num_workers=4)\n    \n    '''def val_dataloader(self):\n        return DataLoader(self.dataset_val, batch_size=batch_size, shuffle=True, num_workers=4)'''","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:12:38.987386Z","iopub.execute_input":"2021-07-24T06:12:38.987914Z","iopub.status.idle":"2021-07-24T06:12:39.004353Z","shell.execute_reply.started":"2021-07-24T06:12:38.987874Z","shell.execute_reply":"2021-07-24T06:12:39.003515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train","metadata":{}},{"cell_type":"code","source":"dm = SRDataModule()\nmodel = PretrainGenerator()","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:12:39.006264Z","iopub.execute_input":"2021-07-24T06:12:39.006642Z","iopub.status.idle":"2021-07-24T06:12:39.419864Z","shell.execute_reply.started":"2021-07-24T06:12:39.006604Z","shell.execute_reply":"2021-07-24T06:12:39.418951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_pair = dm.dataset[508]\nlr = img_pair['lr']\nhr = img_pair['hr']\nprint(torch.min(lr), torch.max(lr))\nprint(torch.min(hr), torch.max(hr))\n\nlr = lr.permute(1, 2, 0).detach().numpy()\nplt.imshow(lr)\nplt.show()\n\nhr = hr.permute(1, 2, 0).detach().numpy()\nplt.imshow(hr)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:12:39.421369Z","iopub.execute_input":"2021-07-24T06:12:39.421683Z","iopub.status.idle":"2021-07-24T06:12:39.688517Z","shell.execute_reply.started":"2021-07-24T06:12:39.421646Z","shell.execute_reply":"2021-07-24T06:12:39.68755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = pl.Trainer(max_epochs=10, gpus=1)\ntrainer.fit(model, dm)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:12:39.68991Z","iopub.execute_input":"2021-07-24T06:12:39.690279Z","iopub.status.idle":"2021-07-24T06:21:17.209016Z","shell.execute_reply.started":"2021-07-24T06:12:39.690242Z","shell.execute_reply":"2021-07-24T06:21:17.208148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_pair = dm.dataset[0]\nprint(torch.std(model.gen.first_conv.weight))\nlr = img_pair['lr']\nlr = lr.view((1, 3, 32, 32))\nsr = model.gen(lr)\nsr = sr.permute(0, 2, 3, 1).detach().numpy()[0]\nplt.imshow(sr)\nplt.show()\n\nhr = img_pair['hr']\nprint(nn.L1Loss()(hr, torch.from_numpy(sr).permute(2, 0, 1)))\nhr = hr.permute(1, 2, 0).detach().numpy()\nplt.imshow(hr)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-24T06:24:21.173754Z","iopub.execute_input":"2021-07-24T06:24:21.174192Z","iopub.status.idle":"2021-07-24T06:24:21.242101Z","shell.execute_reply.started":"2021-07-24T06:24:21.174091Z","shell.execute_reply":"2021-07-24T06:24:21.240321Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-1db06eeaabfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg_pair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_conv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'dm' is not defined"],"ename":"NameError","evalue":"name 'dm' is not defined","output_type":"error"}]}]}